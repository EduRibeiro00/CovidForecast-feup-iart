{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ExpSineSquared\n",
    "from sklearn.kernel_ridge import KernelRidge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(inputs, outputs):\n",
    "    return train_test_split(inputs, outputs, test_size=0.25, shuffle=True)\n",
    "\n",
    "def train_model(params, search, in_train, out_train):\n",
    "    start = time.time()\n",
    "    search.fit(in_train, out_train)\n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    print('Elapsed time: {}mins'.format(elapsed_time / 60))\n",
    "    print('Best score: {}'.format(search.best_score_))\n",
    "    print('Best parameters: {}'.format(search.best_params_))\n",
    "    return search.best_estimator_\n",
    "\n",
    "    #rf_estimator = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                          #max_depth=100, max_features=3, max_leaf_nodes=None,\n",
    "                          #max_samples=None, min_impurity_decrease=0.0,\n",
    "                          #min_impurity_split=None, min_samples_leaf=3,\n",
    "                          #min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
    "                          #n_estimators=100, n_jobs=None, oob_score=False,\n",
    "                          #random_state=None, verbose=0, warm_start=False)\n",
    "    #rf_estimator.fit(in_conf_train, out_conf_train)\n",
    "    #return rf_estimator\n",
    "    \n",
    "def check_results_test(estimator, in_test, out_test, label):\n",
    "    estimator_pred = estimator.predict(in_test)\n",
    "    plt.plot(out_test)\n",
    "    plt.plot(estimator_pred)\n",
    "    plt.legend(['Input Data', label])\n",
    "    print('MAE:', mean_absolute_error(out_test, estimator_pred))\n",
    "    print('MSE:',mean_squared_error(out_test, estimator_pred))\n",
    "    print('RMSE:', math.sqrt(mean_squared_error(out_test, estimator_pred)))\n",
    "    print('R^2:', r2_score(out_test, estimator_pred))\n",
    "    \n",
    "def plot_cross_val_score(estimator, inputs, outputs, number_cv):\n",
    "    cv_scores = cross_val_score(estimator, inputs, outputs, cv=number_cv)\n",
    "    plt.hist(cv_scores)\n",
    "    plt.title('Average score: {}'.format(np.mean(cv_scores)))\n",
    "    \n",
    "def calc_cumulative(in_list):\n",
    "    out_list = []\n",
    "    for idx, elem in enumerate(in_list):\n",
    "        if idx == 0:\n",
    "            out_list.append(elem)\n",
    "        else:\n",
    "            out_list.append(elem + out_list[idx - 1])\n",
    "    return out_list\n",
    "    \n",
    "def plot_predictions_for_country(df, country, estimator, inputs_list, output, label_out, label_pred, title, cumulative=False):\n",
    "    country_df = df.loc[df[\"Country/Region\"] == country]\n",
    "    country_inputs = country_df[inputs_list].values\n",
    "    country_outputs = country_df[output].values\n",
    "    days_list = df[\"Num_days_from_begin\"].unique()\n",
    "    country_pred_output = estimator.predict(country_inputs) \n",
    "\n",
    "    first_day = df[\"Date\"].min()\n",
    "    last_day = df[\"Date\"].max()\n",
    "\n",
    "    if cumulative:\n",
    "        country_pred_output = calc_cumulative(country_pred_output)\n",
    "    \n",
    "    print('MAE:', mean_absolute_error(country_outputs, country_pred_output))\n",
    "    print('MSE:',mean_squared_error(country_outputs, country_pred_output))\n",
    "    print('RMSE:', math.sqrt(mean_squared_error(country_outputs, country_pred_output)))\n",
    "    print('R^2:', r2_score(country_outputs, country_pred_output))\n",
    "\n",
    "    plt.plot(days_list, country_outputs, color='blue', label=label_out)\n",
    "    plt.plot(days_list, country_pred_output, color='green', label=label_pred)\n",
    "    plt.xlabel(\"Number of days since {}\".format(first_day))\n",
    "    plt.ylabel(\"# of Cases\")\n",
    "    plt.title(title + \"(as of {})\".format(last_day))\n",
    "    plt.legend()\n",
    "    \n",
    "def plot_learning_curve(estimator, inputs, outputs):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator=estimator, X=inputs, y=outputs,\n",
    "                                       groups=None, \n",
    "                                       train_sizes=np.array([0.1, 0.33, 0.55, 0.78, 1. ]),\n",
    "                                       cv=None, scoring=None, exploit_incremental_learning=False, \n",
    "                                       n_jobs=None, pre_dispatch='all', verbose=0, shuffle=True,\n",
    "                                       random_state=None, error_score=np.nan, return_times=False)\n",
    "\n",
    "    train_scores_mean = train_scores.mean(axis=1)\n",
    "    test_scores_mean = test_scores.mean(axis=1)\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, label='Training score')\n",
    "    plt.plot(train_sizes, test_scores_mean, label='Test score')\n",
    "\n",
    "    plt.ylabel('Score', fontsize=14)\n",
    "    plt.xlabel('Training set size', fontsize=14)\n",
    "    title = 'Learning curves for a ' + str(estimator).split('(')[0] + ' model'\n",
    "    plt.title(title, fontsize=18, y=1.03)\n",
    "    plt.legend()\n",
    "    \n",
    "def plot_pred_diff(df, estimator, country, inputs_list, output):\n",
    "    country_df = df.loc[df[\"Country/Region\"] == country]\n",
    "    country_inputs = country_df[inputs_list].values\n",
    "    country_outputs = country_df[output].values\n",
    "    days_list = df[\"Num_days_from_begin\"].unique()\n",
    "    country_pred_output = estimator.predict(country_inputs)\n",
    "\n",
    "    first_day = df[\"Date\"].min()\n",
    "    last_day = df[\"Date\"].max()\n",
    "\n",
    "    diff_list = np.subtract(country_outputs, country_pred_output)\n",
    "    plt.bar(days_list, diff_list, color='blue', label=\"\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lat_norm</th>\n",
       "      <th>Long</th>\n",
       "      <th>Long_norm</th>\n",
       "      <th>Date</th>\n",
       "      <th>Num_days_from_begin</th>\n",
       "      <th>Num_days_from_begin_norm</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>...</th>\n",
       "      <th>Confirmed_inc_day_before</th>\n",
       "      <th>Confirmed_inc_day_before_norm</th>\n",
       "      <th>Deaths_inc</th>\n",
       "      <th>Deaths_inc_norm</th>\n",
       "      <th>Deaths_inc_day_before</th>\n",
       "      <th>Deaths_inc_day_before_norm</th>\n",
       "      <th>Recovered_inc</th>\n",
       "      <th>Recovered_inc_norm</th>\n",
       "      <th>Recovered_inc_day_before</th>\n",
       "      <th>Recovered_inc_day_before_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>0.471083</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>0.597360</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.717183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>0.798304</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>-0.039787</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.717183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alberta (Canada)</td>\n",
       "      <td>53.9333</td>\n",
       "      <td>1.311212</td>\n",
       "      <td>-116.5765</td>\n",
       "      <td>-1.983201</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.717183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>0.271776</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>-0.302833</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.717183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.5063</td>\n",
       "      <td>0.852605</td>\n",
       "      <td>1.5218</td>\n",
       "      <td>-0.304791</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.717183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30619</th>\n",
       "      <td>Yukon (Canada)</td>\n",
       "      <td>64.2823</td>\n",
       "      <td>1.726554</td>\n",
       "      <td>-135.0000</td>\n",
       "      <td>-2.245035</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>115</td>\n",
       "      <td>1.717183</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.116999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30620</th>\n",
       "      <td>Yunnan (China)</td>\n",
       "      <td>24.9740</td>\n",
       "      <td>0.148971</td>\n",
       "      <td>101.4870</td>\n",
       "      <td>1.115912</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>115</td>\n",
       "      <td>1.717183</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.116999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30621</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>-15.4167</td>\n",
       "      <td>-1.472053</td>\n",
       "      <td>28.2833</td>\n",
       "      <td>0.075543</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>115</td>\n",
       "      <td>1.717183</td>\n",
       "      <td>679</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.116999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110177</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30622</th>\n",
       "      <td>Zhejiang (China)</td>\n",
       "      <td>29.1832</td>\n",
       "      <td>0.317901</td>\n",
       "      <td>120.0934</td>\n",
       "      <td>1.380346</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>115</td>\n",
       "      <td>1.717183</td>\n",
       "      <td>1268</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.116999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30623</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-20.0000</td>\n",
       "      <td>-1.655997</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.099941</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>115</td>\n",
       "      <td>1.717183</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.113089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.110177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.121373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30624 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country/Region      Lat  Lat_norm      Long  Long_norm        Date  \\\n",
       "0           Afghanistan  33.0000  0.471083   65.0000   0.597360  2020-01-22   \n",
       "1               Albania  41.1533  0.798304   20.1683  -0.039787  2020-01-22   \n",
       "2      Alberta (Canada)  53.9333  1.311212 -116.5765  -1.983201  2020-01-22   \n",
       "3               Algeria  28.0339  0.271776    1.6596  -0.302833  2020-01-22   \n",
       "4               Andorra  42.5063  0.852605    1.5218  -0.304791  2020-01-22   \n",
       "...                 ...      ...       ...       ...        ...         ...   \n",
       "30619    Yukon (Canada)  64.2823  1.726554 -135.0000  -2.245035  2020-05-16   \n",
       "30620    Yunnan (China)  24.9740  0.148971  101.4870   1.115912  2020-05-16   \n",
       "30621            Zambia -15.4167 -1.472053   28.2833   0.075543  2020-05-16   \n",
       "30622  Zhejiang (China)  29.1832  0.317901  120.0934   1.380346  2020-05-16   \n",
       "30623          Zimbabwe -20.0000 -1.655997   30.0000   0.099941  2020-05-16   \n",
       "\n",
       "       Num_days_from_begin  Num_days_from_begin_norm  Confirmed  Deaths  ...  \\\n",
       "0                        0                 -1.717183          0       0  ...   \n",
       "1                        0                 -1.717183          0       0  ...   \n",
       "2                        0                 -1.717183          0       0  ...   \n",
       "3                        0                 -1.717183          0       0  ...   \n",
       "4                        0                 -1.717183          0       0  ...   \n",
       "...                    ...                       ...        ...     ...  ...   \n",
       "30619                  115                  1.717183         11       0  ...   \n",
       "30620                  115                  1.717183        185       2  ...   \n",
       "30621                  115                  1.717183        679       7  ...   \n",
       "30622                  115                  1.717183       1268       1  ...   \n",
       "30623                  115                  1.717183         42       4  ...   \n",
       "\n",
       "       Confirmed_inc_day_before  Confirmed_inc_day_before_norm  Deaths_inc  \\\n",
       "0                           NaN                            NaN         0.0   \n",
       "1                           NaN                            NaN         0.0   \n",
       "2                           NaN                            NaN         0.0   \n",
       "3                           NaN                            NaN         0.0   \n",
       "4                           NaN                            NaN         0.0   \n",
       "...                         ...                            ...         ...   \n",
       "30619                       0.0                      -0.116999         0.0   \n",
       "30620                       0.0                      -0.116999         0.0   \n",
       "30621                       0.0                      -0.116999         0.0   \n",
       "30622                       0.0                      -0.116999         0.0   \n",
       "30623                       5.0                      -0.113089         0.0   \n",
       "\n",
       "       Deaths_inc_norm  Deaths_inc_day_before  Deaths_inc_day_before_norm  \\\n",
       "0            -0.110666                    NaN                         NaN   \n",
       "1            -0.110666                    NaN                         NaN   \n",
       "2            -0.110666                    NaN                         NaN   \n",
       "3            -0.110666                    NaN                         NaN   \n",
       "4            -0.110666                    NaN                         NaN   \n",
       "...                ...                    ...                         ...   \n",
       "30619        -0.110666                    0.0                   -0.110177   \n",
       "30620        -0.110666                    0.0                   -0.110177   \n",
       "30621        -0.110666                    0.0                   -0.110177   \n",
       "30622        -0.110666                    0.0                   -0.110177   \n",
       "30623        -0.110666                    0.0                   -0.110177   \n",
       "\n",
       "       Recovered_inc  Recovered_inc_norm  Recovered_inc_day_before  \\\n",
       "0                0.0           -0.121130                       NaN   \n",
       "1                0.0           -0.121130                       NaN   \n",
       "2                NaN                 NaN                       NaN   \n",
       "3                0.0           -0.121130                       NaN   \n",
       "4                0.0           -0.121130                       NaN   \n",
       "...              ...                 ...                       ...   \n",
       "30619            NaN                 NaN                       NaN   \n",
       "30620            0.0           -0.121130                       0.0   \n",
       "30621           59.0            0.003578                       0.0   \n",
       "30622            0.0           -0.121130                       0.0   \n",
       "30623            0.0           -0.121130                       0.0   \n",
       "\n",
       "       Recovered_inc_day_before_norm  \n",
       "0                                NaN  \n",
       "1                                NaN  \n",
       "2                                NaN  \n",
       "3                                NaN  \n",
       "4                                NaN  \n",
       "...                              ...  \n",
       "30619                            NaN  \n",
       "30620                      -0.121373  \n",
       "30621                      -0.121373  \n",
       "30622                      -0.121373  \n",
       "30623                      -0.121373  \n",
       "\n",
       "[30624 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load previously processed information into dataframe\n",
    "df = pd.read_csv('data/covid_19_world_processed.csv', delimiter=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47108303,  0.59735963, -1.71718314],\n",
       "       [ 0.79830423, -0.03978737, -1.71718314],\n",
       "       [ 1.3112115 , -1.98320106, -1.71718314],\n",
       "       ...,\n",
       "       [-1.47205293,  0.07554281,  1.71718314],\n",
       "       [ 0.31790115,  1.38034566,  1.71718314],\n",
       "       [-1.65599721,  0.09994051,  1.71718314]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the inputs of the data for the machine learning algorithm\n",
    "inputs = df[[\"Lat_norm\", \"Long_norm\", \"Num_days_from_begin_norm\"]].values\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 25.,  0.,  0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the output for the machine learning algorithm (confirmed inc cases)\n",
    "outputs = df[\"Confirmed_inc\"].values\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "in_conf_train, in_conf_test, out_conf_train, out_conf_test = split_train_test(inputs, outputs)\n",
    "\n",
    "# NOTE: actually, the \"testing\" set will be used for \"manual\" testing and plotting, while the training set will be\n",
    "# further divided in training and testing sets, in order to perform k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1,\n",
       " 'coef0': 1,\n",
       " 'degree': 3,\n",
       " 'gamma': None,\n",
       " 'kernel': 'linear',\n",
       " 'kernel_params': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create K-Nearest Neighbours instance, and check the hyper parameters)\n",
    "kr = KernelRidge()\n",
    "kr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# do hyper parameter tuning with the K-Nearest, using cross validation\n",
    "param_grid = {\"alpha\": [1e0, 1e-1, 1e-2, 1e-3],\n",
    "              \"kernel\": [ExpSineSquared(l, p)\n",
    "                         for l in np.logspace(-2, 2, 10)\n",
    "                         for p in np.logspace(0, 2, 10)]}\n",
    "search =RandomizedSearchCV(kr, param_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=10, verbose=1)\n",
    "kr_estimator = train_model(param_grid, search, in_conf_train, out_conf_train)\n",
    "kr_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results_test(kr_estimator, in_conf_test, out_conf_test, 'Kernel Ridge Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_for_country(\n",
    "    df, \"US\", kr_estimator, \n",
    "    [\"Lat_norm\", \"Long_norm\", \"Num_days_from_begin_norm\"], \n",
    "    \"Confirmed\",\n",
    "    \"Actual Confirmed Cases\", \n",
    "    \"Predicted (Random Forest)\", \n",
    "    \"US Confirmed Cases vs Prediction from Nearest Neighbour\",\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_kernel = ExpSineSquared(1.0, 5.0, periodicity_bounds=(1e-2, 1e1)) \\\n",
    "    + WhiteKernel(1e-1)\n",
    "gpr = GaussianProcessRegressor(kernel=gp_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " gpr.fit(in_train, out_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_estimator = gpr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results_test(gpr_estimator, in_conf_test, out_conf_test, 'Kernel Ridge Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_for_country(\n",
    "    df, \"US\", gpr_estimator, \n",
    "    [\"Lat_norm\", \"Long_norm\", \"Num_days_from_begin_norm\"], \n",
    "    \"Confirmed\",\n",
    "    \"Actual Confirmed Cases\", \n",
    "    \"Predicted (Random Forest)\", \n",
    "    \"US Confirmed Cases vs Prediction from Nearest Neighbour\",\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
